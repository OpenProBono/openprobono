{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# OpenProBono RAG Evaluation\n",
    "\n",
    "This notebook was created using https://huggingface.co/learn/cookbook/en/rag_evaluation as a guide. Anything inside double quotations is a direct quote from this source, and much of the text is paraphrased. Prompts and code have been modified for use by OpenProBono.\n",
    "\n",
    "### 0: Install and import dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q tqdm openai pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/njc/Documents/programming/opb/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import chat_models\n",
    "import encoders\n",
    "import milvusdb\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Load our knowledge base\n",
    "\n",
    "For this step, we have already loaded the data we wish to evaluate into a `Collection` in our Milvus vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = milvusdb.COURTROOM5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1: Load sources\n",
    " \n",
    "We have a list of sources we use to filter the documents so we can generate questions about one source at a time. The sources can be files or URLs. We load the list of sources for this example from a file named `urls`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"urls\").open() as f:\n",
    "    urls = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2: Load documents\n",
    "\n",
    "Now that we loaded our source URLs, we can write a function that will get the chunks associated the source from Milvus. We use a boolean expression filter to get the right chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_url_documents(url: str):\n",
    "    expr = f\"metadata['url']=='{url}'\"\n",
    "    hits = milvusdb.get_expr(collection_name, expr)[\"result\"]\n",
    "    for i in range(len(hits)):\n",
    "        hits[i][\"url\"] = hits[i][\"metadata\"][\"url\"]\n",
    "        hits[i][\"page_number\"] = hits[i][\"metadata\"][\"page_number\"]\n",
    "        del hits[i][\"pk\"]\n",
    "        del hits[i][\"metadata\"]\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3: Setup question generation agents\n",
    "\n",
    "We will use `gpt-3.5-turbo` for question generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = openai.OpenAI()\n",
    "\n",
    "def call_llm(client: openai.OpenAI, prompt: str, model: str = chat_models.GPT_3_5, temperature: int = 0.7, extra_messages: list = []):\n",
    "    prompt_msg = {\"role\": \"system\", \"content\": prompt}\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[prompt_msg, *extra_messages],\n",
    "        max_tokens=1000,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the prompt that will be given to our LLM to generate questions about our documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_generation_prompt = \"\"\"\n",
    "Your task is to write a factoid question and an answer given a context.\n",
    "Your factoid question should be answerable with a specific, concise piece of factual information from the context.\n",
    "Your factoid question should be formulated in the same style as questions users could ask in a search engine.\n",
    "This means that your factoid question MUST NOT mention something like \"according to the passage\" or \"context\".\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Output:::\n",
    "Factoid question: (your factoid question)\n",
    "Answer: (your answer to the factoid question)\n",
    "\n",
    "Now here is the context.\n",
    "\n",
    "Context: {context}\\n\n",
    "Output:::\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate 3 samples to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 3 QA couples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "N_GENERATIONS = 3  # We intentionally generate only 3 QA couples here for cost and time considerations\n",
    "\n",
    "print(f\"Generating {N_GENERATIONS} QA couples...\")\n",
    "\n",
    "outputs = []\n",
    "for sampled_context in tqdm(random.sample(load_url_documents(urls[4]), N_GENERATIONS)):\n",
    "    # Generate QA couple\n",
    "    output_QA_couple = call_llm(llm_client, QA_generation_prompt.format(context=sampled_context[\"text\"]))\n",
    "    try:\n",
    "        question = output_QA_couple.split(\"Factoid question: \")[-1].split(\"Answer: \")[0].rstrip()\n",
    "        answer = output_QA_couple.split(\"Answer: \")[-1]\n",
    "        assert len(answer) < 300, \"Answer is too long\"\n",
    "        outputs.append(\n",
    "            {\n",
    "                \"context\": sampled_context[\"text\"],\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"source_doc\": sampled_context[\"url\"],\n",
    "            }\n",
    "        )\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>source_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(c)\\n\\nService as a law enforcement officer shall constitute service as (i) a \"criminal justice officer\" as defined in G.S. 17C-2(c) and (ii) a \"law enforcement officer\" for purposes of Article 12E of Chapter 143 of the General Statutes. For purposes of Article 12E of Chapter 143 of the General Statutes, the term \"employer,\" as defined in G.S. 143-166.50, shall be construed to include the Eastern Band of Cherokee Indians with respect to law enforcement officers.\\n\\n(d)\\n\\nA law enforcement officer may be enjoined from exercising his authority under color of State law pursuant to Article 13 of Chapter 160A of the General Statutes for the reasons set forth in G.S. 128-16 and pursuant to the provisions of Article 2 of Chapter 128 of the General Statutes.\\n\\n(e)\\n\\n(f)\\n\\nNothing contained in this Chapter or in Article 13 of Chapter 160A of the General\\n\\nStatutes shall be construed as doing any of the following:\\n\\n(1)\\n\\n(2)\\n\\nLimiting or revoking the authority of the Eastern Band of Cherokee Indians, the Cherokee Police Department, the Tribal Alcohol Law Enforcement Division of the Eastern Band of the Cherokee Indians, the Natural Resources Enforcement Agency of the Eastern Band of the Cherokee Indians, or any law enforcement officers or other persons appointed or employed by those entities, in the exercise of their inherent powers of self-government, or exercise of authority conferred by federal law, regulation, or common law. Modifying, either by way of enlargement or limitation, the jurisdiction of the Cherokee Tribal Courts.</td>\n",
       "      <td>What constitutes service as a law enforcement officer for purposes of Article 12E of Chapter 143 of the General Statutes?</td>\n",
       "      <td>Service as a law enforcement officer shall constitute service as a \"criminal justice officer\" as defined in G.S. 17C-2(c) and a \"law enforcement officer\" for purposes of Article 12E of Chapter 143 of the General Statutes.</td>\n",
       "      <td>https://www.ncleg.gov/EnactedLegislation/Statutes/PDF/ByChapter/Chapter_1E.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chapter 1E.\\n\\nEastern Band of Cherokee Indians.\\n\\nArticle 1.\\n\\nFull Faith and Credit.\\n\\nÂ§ 1E-1. Full faith and credit.\\n\\nThe courts of this State shall give full faith and credit to a judgment, decree, or order signed by a judicial officer of the Eastern Band of Cherokee Indians and filed in the Cherokee Tribal Courts to the same extent as is given a judgment, decree, or order of another state, subject to the provisions of subsections (b) and (c) of this section; provided that the judgments, decrees, and orders of the courts of this State are given full faith and credit by the Tribal Courts of the Eastern Band of Cherokee Indians.\\n\\n(a)\\n\\nJudgments, decrees, and orders specified in subsection (a) of this section shall be given full faith and credit subject to the provisions of G.S. 1C-1705 and G.S. 1C-1708 and shall be considered a foreign judgment for purposes of these statutes.\\n\\n(b)\\n\\nAny limited driving privilege signed and issued by a Judge or Justice of the Cherokee Tribal Courts in accordance with the applicable provisions of Chapter 20 of the General Statutes and filed in the Cherokee Tribal Courts Clerk's Office shall be valid and given full faith and credit as specified in subsection (a) of this section. For purposes of this subsection, any reference to the issuing \"judge\" or \"court\" in the applicable provisions of Chapter 20 of the General Statutes shall be construed to mean the appropriate Judge or Justice in the Cherokee Tribal Courts or the appropriate Cherokee Tribal Court. (2001-456, s. 1; 2015-287, s. 1.)</td>\n",
       "      <td>What must the courts of North Carolina give to a judgment, decree, or order signed by a judicial officer of the Eastern Band of Cherokee Indians and filed in the Cherokee Tribal Courts?</td>\n",
       "      <td>Full faith and credit.</td>\n",
       "      <td>https://www.ncleg.gov/EnactedLegislation/Statutes/PDF/ByChapter/Chapter_1E.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the Cherokee Marshals Service,\\n\\nÂ§ 1E-12. Qualification of law enforcement officers; limitations of authority.\\n\\nFor purposes of this section, \"law enforcement officer\" means any person appointed or employed as (i) Chief of Police of the Cherokee Police Department, Chief of the Cherokee Marshals Service, Chief of the Tribal Alcohol Law Enforcement Division of the Eastern Band of the Cherokee Indians, or Chief of the Natural Resources Enforcement Agency of the Eastern Band of the Cherokee Indians or (ii) a police officer, auxiliary police officer, marshal, alcohol law enforcement agent, reserve alcohol law enforcement agent, or resources officer with the Cherokee Police Department, the Cherokee Marshals Service, the Tribal Alcohol Law Enforcement Division of the Eastern Band of the Cherokee Indians, or the Natural Resources Enforcement Agency of the Eastern Band of the Cherokee Indians.\\n\\n(a)\\n\\nA law enforcement officer shall, prior to the exercise of the officer's authority pursuant to Article 13 of Chapter 160A of the General Statutes, comply with the provisions of Article 1 of Chapter 17C of the General Statutes and any rules or regulations adopted pursuant to the authority of Article 1 of Chapter 17C of the General Statutes. The courts of this State shall have the</td>\n",
       "      <td>What is the definition of a \"law enforcement officer\" within the Cherokee Marshals Service?</td>\n",
       "      <td>Any person appointed or employed as Chief of the Cherokee Marshals Service or a police officer, auxiliary police officer, marshal, alcohol law enforcement agent, reserve alcohol law enforcement agent, or resources officer with the Cherokee Marshals Service.</td>\n",
       "      <td>https://www.ncleg.gov/EnactedLegislation/Statutes/PDF/ByChapter/Chapter_1E.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                context  \\\n",
       "0    (c)\\n\\nService as a law enforcement officer shall constitute service as (i) a \"criminal justice officer\" as defined in G.S. 17C-2(c) and (ii) a \"law enforcement officer\" for purposes of Article 12E of Chapter 143 of the General Statutes. For purposes of Article 12E of Chapter 143 of the General Statutes, the term \"employer,\" as defined in G.S. 143-166.50, shall be construed to include the Eastern Band of Cherokee Indians with respect to law enforcement officers.\\n\\n(d)\\n\\nA law enforcement officer may be enjoined from exercising his authority under color of State law pursuant to Article 13 of Chapter 160A of the General Statutes for the reasons set forth in G.S. 128-16 and pursuant to the provisions of Article 2 of Chapter 128 of the General Statutes.\\n\\n(e)\\n\\n(f)\\n\\nNothing contained in this Chapter or in Article 13 of Chapter 160A of the General\\n\\nStatutes shall be construed as doing any of the following:\\n\\n(1)\\n\\n(2)\\n\\nLimiting or revoking the authority of the Eastern Band of Cherokee Indians, the Cherokee Police Department, the Tribal Alcohol Law Enforcement Division of the Eastern Band of the Cherokee Indians, the Natural Resources Enforcement Agency of the Eastern Band of the Cherokee Indians, or any law enforcement officers or other persons appointed or employed by those entities, in the exercise of their inherent powers of self-government, or exercise of authority conferred by federal law, regulation, or common law. Modifying, either by way of enlargement or limitation, the jurisdiction of the Cherokee Tribal Courts.   \n",
       "1  Chapter 1E.\\n\\nEastern Band of Cherokee Indians.\\n\\nArticle 1.\\n\\nFull Faith and Credit.\\n\\nÂ§ 1E-1. Full faith and credit.\\n\\nThe courts of this State shall give full faith and credit to a judgment, decree, or order signed by a judicial officer of the Eastern Band of Cherokee Indians and filed in the Cherokee Tribal Courts to the same extent as is given a judgment, decree, or order of another state, subject to the provisions of subsections (b) and (c) of this section; provided that the judgments, decrees, and orders of the courts of this State are given full faith and credit by the Tribal Courts of the Eastern Band of Cherokee Indians.\\n\\n(a)\\n\\nJudgments, decrees, and orders specified in subsection (a) of this section shall be given full faith and credit subject to the provisions of G.S. 1C-1705 and G.S. 1C-1708 and shall be considered a foreign judgment for purposes of these statutes.\\n\\n(b)\\n\\nAny limited driving privilege signed and issued by a Judge or Justice of the Cherokee Tribal Courts in accordance with the applicable provisions of Chapter 20 of the General Statutes and filed in the Cherokee Tribal Courts Clerk's Office shall be valid and given full faith and credit as specified in subsection (a) of this section. For purposes of this subsection, any reference to the issuing \"judge\" or \"court\" in the applicable provisions of Chapter 20 of the General Statutes shall be construed to mean the appropriate Judge or Justice in the Cherokee Tribal Courts or the appropriate Cherokee Tribal Court. (2001-456, s. 1; 2015-287, s. 1.)   \n",
       "2                                                                                                                                                                                                                                                                           the Cherokee Marshals Service,\\n\\nÂ§ 1E-12. Qualification of law enforcement officers; limitations of authority.\\n\\nFor purposes of this section, \"law enforcement officer\" means any person appointed or employed as (i) Chief of Police of the Cherokee Police Department, Chief of the Cherokee Marshals Service, Chief of the Tribal Alcohol Law Enforcement Division of the Eastern Band of the Cherokee Indians, or Chief of the Natural Resources Enforcement Agency of the Eastern Band of the Cherokee Indians or (ii) a police officer, auxiliary police officer, marshal, alcohol law enforcement agent, reserve alcohol law enforcement agent, or resources officer with the Cherokee Police Department, the Cherokee Marshals Service, the Tribal Alcohol Law Enforcement Division of the Eastern Band of the Cherokee Indians, or the Natural Resources Enforcement Agency of the Eastern Band of the Cherokee Indians.\\n\\n(a)\\n\\nA law enforcement officer shall, prior to the exercise of the officer's authority pursuant to Article 13 of Chapter 160A of the General Statutes, comply with the provisions of Article 1 of Chapter 17C of the General Statutes and any rules or regulations adopted pursuant to the authority of Article 1 of Chapter 17C of the General Statutes. The courts of this State shall have the   \n",
       "\n",
       "                                                                                                                                                                                    question  \\\n",
       "0                                                                  What constitutes service as a law enforcement officer for purposes of Article 12E of Chapter 143 of the General Statutes?   \n",
       "1  What must the courts of North Carolina give to a judgment, decree, or order signed by a judicial officer of the Eastern Band of Cherokee Indians and filed in the Cherokee Tribal Courts?   \n",
       "2                                                                                                What is the definition of a \"law enforcement officer\" within the Cherokee Marshals Service?   \n",
       "\n",
       "                                                                                                                                                                                                                                                              answer  \\\n",
       "0                                      Service as a law enforcement officer shall constitute service as a \"criminal justice officer\" as defined in G.S. 17C-2(c) and a \"law enforcement officer\" for purposes of Article 12E of Chapter 143 of the General Statutes.   \n",
       "1                                                                                                                                                                                                                                             Full faith and credit.   \n",
       "2  Any person appointed or employed as Chief of the Cherokee Marshals Service or a police officer, auxiliary police officer, marshal, alcohol law enforcement agent, reserve alcohol law enforcement agent, or resources officer with the Cherokee Marshals Service.   \n",
       "\n",
       "                                                                       source_doc  \n",
       "0  https://www.ncleg.gov/EnactedLegislation/Statutes/PDF/ByChapter/Chapter_1E.pdf  \n",
       "1  https://www.ncleg.gov/EnactedLegislation/Statutes/PDF/ByChapter/Chapter_1E.pdf  \n",
       "2  https://www.ncleg.gov/EnactedLegislation/Statutes/PDF/ByChapter/Chapter_1E.pdf  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(outputs).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Setup question critique agents\n",
    "\n",
    "The generated questions can be flawed in many ways. We use an agent to determine if a generated question meets the following criteria, given in [this paper](https://huggingface.co/papers/2312.10003):\n",
    "\n",
    "- **Groundedness**: can the question be answered from the given context?\n",
    "- **Relevance**: is the question relevant to users? For instance, *\"What are some of Thomas Jefferson's beliefs regarding the rights and liberties of individuals?\"* is not relevant for OpenProBono users.\n",
    "- **Standalone**: is the question understandable free of any context, for someone with domain knowledge/Internet access? For instance, *\"What does the term 'legal entity' refer to in this statute?\"* is tailored for a particular statute, but unclear by itself.\n",
    "\n",
    "\"We systematically score functions with all these agents, and whenever the score is too low for any one of the agents, we eliminate the question from our eval dataset.\n",
    "\n",
    "ðŸ’¡ ***When asking the agents to output a score, we first ask them to produce its rationale. This will help us verify scores, but most importantly, asking it to first output rationale gives the model more tokens to think and elaborate an answer before summarizing it into a single score token.***\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_groundedness_critique_prompt = \"\"\"\n",
    "You will be given a context and a question.\n",
    "Your task is to provide a 'total rating' scoring how well one can answer the given question unambiguously with the given context.\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question is not answerable at all given the context, and 5 means that the question is clearly and unambiguously answerable with the context.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (your rating, as a number between 1 and 5)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
    "\n",
    "Now here are the question and context.\n",
    "\n",
    "Question: {question}\\n\n",
    "Context: {context}\\n\n",
    "Answer::: \"\"\"\n",
    "\n",
    "question_relevance_critique_prompt = \"\"\"\n",
    "You will be given a question.\n",
    "Your task is to provide a 'total rating' representing how useful this question can be to people learning about the legal system.\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question is not useful at all, and 5 means that the question is extremely useful.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (your rating, as a number between 1 and 5)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
    "\n",
    "Now here is the question.\n",
    "\n",
    "Question: {question}\\n\n",
    "Answer::: \"\"\"\n",
    "\n",
    "question_standalone_critique_prompt = \"\"\"\n",
    "You will be given a question.\n",
    "Your task is to provide a 'total rating' representing how context-independent this question is.\n",
    "Give your answer on a scale of 1 to 5, where 1 means that the question depends on additional information to be understood, and 5 means that the question makes sense by itself.\n",
    "For instance, if the question refers to a particular setting, like 'in the context' or 'in the document', the rating must be 1.\n",
    "The questions can contain specific legal definitions or entities like trier of fact or the Board of County Commissioners and still be a 5: it must simply be clear to an operator with access to legal documents what the question is about.\n",
    "\n",
    "For instance, \"Who decides the arbitration location without agreement?\" should receive a 1, since there is an implicit mention of a context, thus the question is not independent from the context.\n",
    "\n",
    "Provide your answer as follows:\n",
    "\n",
    "Answer:::\n",
    "Evaluation: (your rationale for the rating, as a text)\n",
    "Total rating: (your rating, as a number between 1 and 5)\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
    "\n",
    "Now here is the question.\n",
    "\n",
    "Question: {question}\\n\n",
    "Answer::: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating critique for each QA couple...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:11<00:00,  3.68s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating critique for each QA couple...\")\n",
    "for output in tqdm(outputs):\n",
    "    evaluations = {\n",
    "        \"groundedness\": call_llm(\n",
    "            llm_client,\n",
    "            question_groundedness_critique_prompt.format(context=output[\"context\"], question=output[\"question\"]),\n",
    "        ),\n",
    "        \"relevance\": call_llm(\n",
    "            llm_client,\n",
    "            question_relevance_critique_prompt.format(question=output[\"question\"]),\n",
    "        ),\n",
    "        \"standalone\": call_llm(\n",
    "            llm_client,\n",
    "            question_standalone_critique_prompt.format(question=output[\"question\"]),\n",
    "        ),\n",
    "    }\n",
    "    try:\n",
    "        for criterion, evaluation in evaluations.items():\n",
    "            score, eval = (\n",
    "                int(evaluation.split(\"Total rating: \")[-1].strip()),\n",
    "                evaluation.split(\"Total rating: \")[-2].split(\"Evaluation: \")[1],\n",
    "            )\n",
    "            output.update(\n",
    "                {\n",
    "                    f\"{criterion}_score\": score,\n",
    "                    f\"{criterion}_eval\": eval,\n",
    "                }\n",
    "            )\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>groundedness_score</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>standalone_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What constitutes service as a law enforcement officer for purposes of Article 12E of Chapter 143 of the General Statutes?</td>\n",
       "      <td>Service as a law enforcement officer shall constitute service as a \"criminal justice officer\" as defined in G.S. 17C-2(c) and a \"law enforcement officer\" for purposes of Article 12E of Chapter 143 of the General Statutes.</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What must the courts of North Carolina give to a judgment, decree, or order signed by a judicial officer of the Eastern Band of Cherokee Indians and filed in the Cherokee Tribal Courts?</td>\n",
       "      <td>Full faith and credit.</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the definition of a \"law enforcement officer\" within the Cherokee Marshals Service?</td>\n",
       "      <td>Any person appointed or employed as Chief of the Cherokee Marshals Service or a police officer, auxiliary police officer, marshal, alcohol law enforcement agent, reserve alcohol law enforcement agent, or resources officer with the Cherokee Marshals Service.</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                    question  \\\n",
       "0                                                                  What constitutes service as a law enforcement officer for purposes of Article 12E of Chapter 143 of the General Statutes?   \n",
       "1  What must the courts of North Carolina give to a judgment, decree, or order signed by a judicial officer of the Eastern Band of Cherokee Indians and filed in the Cherokee Tribal Courts?   \n",
       "2                                                                                                What is the definition of a \"law enforcement officer\" within the Cherokee Marshals Service?   \n",
       "\n",
       "                                                                                                                                                                                                                                                              answer  \\\n",
       "0                                      Service as a law enforcement officer shall constitute service as a \"criminal justice officer\" as defined in G.S. 17C-2(c) and a \"law enforcement officer\" for purposes of Article 12E of Chapter 143 of the General Statutes.   \n",
       "1                                                                                                                                                                                                                                             Full faith and credit.   \n",
       "2  Any person appointed or employed as Chief of the Cherokee Marshals Service or a police officer, auxiliary police officer, marshal, alcohol law enforcement agent, reserve alcohol law enforcement agent, or resources officer with the Cherokee Marshals Service.   \n",
       "\n",
       "   groundedness_score  relevance_score  standalone_score  \n",
       "0                   2                5                 1  \n",
       "1                   5                4                 5  \n",
       "2                   5                5                 5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "generated_questions = pd.DataFrame.from_dict(outputs)\n",
    "display(\n",
    "    generated_questions[\n",
    "        [\n",
    "            \"question\",\n",
    "            \"answer\",\n",
    "            \"groundedness_score\",\n",
    "            \"relevance_score\",\n",
    "            \"standalone_score\",\n",
    "        ]\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "Final evaluation dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>groundedness_score</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>standalone_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What must the courts of North Carolina give to a judgment, decree, or order signed by a judicial officer of the Eastern Band of Cherokee Indians and filed in the Cherokee Tribal Courts?</td>\n",
       "      <td>Full faith and credit.</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the definition of a \"law enforcement officer\" within the Cherokee Marshals Service?</td>\n",
       "      <td>Any person appointed or employed as Chief of the Cherokee Marshals Service or a police officer, auxiliary police officer, marshal, alcohol law enforcement agent, reserve alcohol law enforcement agent, or resources officer with the Cherokee Marshals Service.</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                    question  \\\n",
       "1  What must the courts of North Carolina give to a judgment, decree, or order signed by a judicial officer of the Eastern Band of Cherokee Indians and filed in the Cherokee Tribal Courts?   \n",
       "2                                                                                                What is the definition of a \"law enforcement officer\" within the Cherokee Marshals Service?   \n",
       "\n",
       "                                                                                                                                                                                                                                                              answer  \\\n",
       "1                                                                                                                                                                                                                                             Full faith and credit.   \n",
       "2  Any person appointed or employed as Chief of the Cherokee Marshals Service or a police officer, auxiliary police officer, marshal, alcohol law enforcement agent, reserve alcohol law enforcement agent, or resources officer with the Cherokee Marshals Service.   \n",
       "\n",
       "   groundedness_score  relevance_score  standalone_score  \n",
       "1                   5                4                 5  \n",
       "2                   5                5                 5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_questions = generated_questions.loc[\n",
    "    (generated_questions[\"groundedness_score\"] >= 4)\n",
    "    & (generated_questions[\"relevance_score\"] >= 4)\n",
    "    & (generated_questions[\"standalone_score\"] >= 4)\n",
    "]\n",
    "print(\"============================================\")\n",
    "print(\"Final evaluation dataset:\")\n",
    "\n",
    "display(\n",
    "    generated_questions[\n",
    "        [\n",
    "            \"question\",\n",
    "            \"answer\",\n",
    "            \"groundedness_score\",\n",
    "            \"relevance_score\",\n",
    "            \"standalone_score\",\n",
    "        ]\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Build our RAG System\n",
    "\n",
    "As stated previously, our data was already chunked and loaded into Milvus. Now we need an LLM Reader to read retrieved documents and formulate answers to questions.\n",
    "\n",
    "OpenProBono offers various LLM Readers using models offered by OpenAI, HuggingFace, and more. We will create a simple LLM Reader connected to the OpenAI API for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_PROMPT_TEMPLATE = \"\"\"\n",
    "Using the information contained in the context,\n",
    "give a comprehensive answer to the question.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "Provide the number of the source document when relevant.\n",
    "If the answer cannot be deduced from the context, do not give an answer.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_rag(\n",
    "    question: str,\n",
    "    k: int = 7,\n",
    ") -> tuple[str, list[dict]]:\n",
    "    \"\"\"Answer a question using RAG.\"\"\"\n",
    "    # Gather documents with retriever\n",
    "    relevant_docs = milvusdb.query(collection_name, question, k)\n",
    "    relevant_docs = [doc.entity.get(\"text\") for doc in relevant_docs[\"result\"]]  # keep only the text\n",
    "\n",
    "    # Build the final prompt\n",
    "    context = \"\\nExtracted documents:\\n\"\n",
    "    context += \"\".join([f\"Document {i!s}:::\\n\" + doc for i, doc in enumerate(relevant_docs)])\n",
    "\n",
    "    final_prompt = RAG_PROMPT_TEMPLATE.format(question=question, context=context)\n",
    "\n",
    "    # Redact an answer\n",
    "    answer = call_llm(llm_client, final_prompt, temperature=0)\n",
    "\n",
    "    return answer, relevant_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Benchmarking the RAG System\n",
    "\n",
    "\"The RAG system and the evaluation datasets are now ready. The last step is to judge the RAG system's output on this evlauation dataset.\n",
    "\n",
    "To this end, **we setup a judge agent**. âš–ï¸ðŸ¤–\n",
    "\n",
    "Out of the different RAG evaluation metrics, we choose to focus only on faithfulness since it the best end-to-end metric of our system's performance.\n",
    "\n",
    "ðŸ’¡ *In the evaluation prompt, we give a detailed description each metric on the scale 1-5, as is done in Prometheus's prompt template: this helps the model ground its metric precisely. If instead you give the judge LLM a vague scale to work with, the outputs will not be consistent enough between different examples.*\n",
    "\n",
    "ðŸ’¡ *Again, prompting the LLM to output rationale before giving its final score gives it more tokens to help it formalize and elaborate a judgement.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_tests(\n",
    "    eval_dataset: pd.DataFrame,\n",
    "    output_file: str,\n",
    "    verbose: bool | None = True,\n",
    "    test_settings: str = \"\",  # To document the test settings used\n",
    "):\n",
    "    \"\"\"Runs RAG tests on the given dataset and saves the results to the given output file.\"\"\"\n",
    "    try:  # load previous generations if they exist\n",
    "        with Path(output_file).open() as f:\n",
    "            outputs = json.load(f)\n",
    "    except:\n",
    "        outputs = []\n",
    "\n",
    "    for _, example in tqdm(eval_dataset.iterrows(), total=len(eval_dataset)):\n",
    "        question = example[\"question\"]\n",
    "        if question in [output[\"question\"] for output in outputs]:\n",
    "            continue\n",
    "\n",
    "        answer, relevant_docs = answer_with_rag(question)\n",
    "        if verbose:\n",
    "            print(\"=======================================================\")\n",
    "            print(f\"Question: {question}\")\n",
    "            print(f\"Answer: {answer}\")\n",
    "            print(f'True answer: {example[\"answer\"]}')\n",
    "        result = {\n",
    "            \"question\": question,\n",
    "            \"true_answer\": example[\"answer\"],\n",
    "            \"source_doc\": example[\"source_doc\"],\n",
    "            \"generated_answer\": answer,\n",
    "            \"retrieved_docs\": list(relevant_docs),\n",
    "        }\n",
    "        if test_settings:\n",
    "            result[\"test_settings\"] = test_settings\n",
    "        outputs.append(result)\n",
    "\n",
    "        with Path(output_file).open(\"w\") as f:\n",
    "            json.dump(outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_SYSTEM_MSG = \"You are a fair evaluator language model.\"\n",
    "\n",
    "EVALUATION_PROMPT = \"\"\"###Task Description:\n",
    "An instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given.\n",
    "1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n",
    "2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.\n",
    "3. The output format should look as follows: \\\"Feedback: {{write a feedback for criteria}} [RESULT] {{an integer number between 1 and 5}}\\\"\n",
    "4. Please do not generate any other opening, closing, and explanations. Be sure to include [RESULT] in your output.\n",
    "\n",
    "###The instruction to evaluate:\n",
    "{instruction}\n",
    "\n",
    "###Response to evaluate:\n",
    "{response}\n",
    "\n",
    "###Reference Answer (Score 5):\n",
    "{reference_answer}\n",
    "\n",
    "###Score Rubrics:\n",
    "[Is the response correct, accurate, and factual based on the reference answer?]\n",
    "Score 1: The response is completely incorrect, inaccurate, and/or not factual.\n",
    "Score 2: The response is mostly incorrect, inaccurate, and/or not factual.\n",
    "Score 3: The response is somewhat correct, accurate, and/or factual.\n",
    "Score 4: The response is mostly correct, accurate, and factual.\n",
    "Score 5: The response is completely correct, accurate, and factual.\n",
    "\n",
    "###Feedback:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_name = chat_models.GPT_4\n",
    "eval_temperature = 0\n",
    "\n",
    "\n",
    "def evaluate_answers(\n",
    "    answer_path: str,\n",
    "    evaluator_name: str,\n",
    ") -> None:\n",
    "    \"\"\"Evaluate generated answers. Modifies the given answer file in place for better checkpointing.\"\"\"\n",
    "    answers = []\n",
    "    if Path(answer_path).is_file():  # load previous generations if they exist\n",
    "        with Path(answer_path).open() as f:\n",
    "            answers = json.load(f)\n",
    "\n",
    "    for experiment in tqdm(answers):\n",
    "        if f\"eval_score_{evaluator_name}\" in experiment:\n",
    "            continue\n",
    "\n",
    "        eval_prompt = EVALUATION_PROMPT.format(\n",
    "            instruction=experiment[\"question\"],\n",
    "            response=experiment[\"generated_answer\"],\n",
    "            reference_answer=experiment[\"true_answer\"],\n",
    "        )\n",
    "        eval_msg = {\"role\": \"user\", \"content\": eval_prompt}\n",
    "        eval_result = call_llm(llm_client, EVALUATION_SYSTEM_MSG, evaluator_name, eval_temperature, [eval_msg])\n",
    "        feedback, score = (item.strip() for item in eval_result.split(\"[RESULT]\"))\n",
    "        experiment[f\"eval_score_{evaluator_name}\"] = score\n",
    "        experiment[f\"eval_feedback_{evaluator_name}\"] = feedback\n",
    "\n",
    "        with Path(answer_path).open(mode=\"w\") as f:\n",
    "            json.dump(answers, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"ðŸš€ Let's run the tests and evaluate answers!ðŸ‘‡\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation for chunk-hardmax:2500_chunk-softmax:1000_embeddings:text-embedding-3-small_dim:768_rerank:False_reader-model:gpt-3.5-turbo-0125:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 5588.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.42s/it]\n"
     ]
    }
   ],
   "source": [
    "if not Path(\"./output\").exists():\n",
    "    Path.mkdir(\"./output\")\n",
    "\n",
    "settings_name = f\"chunk-hardmax:{2500}_chunk-softmax:{1000}_embeddings:{encoders.OPENAI_3_SMALL}_dim:{768}_rerank:{False}_reader-model:{chat_models.GPT_3_5}\"\n",
    "output_file_name = f\"./output/rag_{settings_name}.json\"\n",
    "\n",
    "print(f\"Running evaluation for {settings_name}:\")\n",
    "\n",
    "run_rag_tests(\n",
    "    eval_dataset=generated_questions,\n",
    "    output_file=output_file_name,\n",
    "    verbose=True,\n",
    "    test_settings=settings_name,\n",
    ")\n",
    "\n",
    "print(\"Running evaluation...\")\n",
    "evaluate_answers(\n",
    "    output_file_name,\n",
    "    evaluator_name,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
